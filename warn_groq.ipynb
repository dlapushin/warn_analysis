{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 click logistics {'has_duplicates': 'False', 'normalized_company_name': '1 click logistics'}\n",
      "10 roads express llc {'has_duplicates': 'False', 'normalized_company_name': '10 roads express'}\n",
      "1266 apartment corp {'has_duplicates': 'False', 'normalized_company_name': '1266 apartment corp'}\n",
      "1888 mills llc {'has_duplicates': 'False', 'normalized_company_name': '1888 mills'}\n",
      "2024 democratic national convention committee {'has_duplicates': 'False', 'normalized_company_name': '2024 democratic national convention committee'}\n",
      "23andme inc {'has_duplicates': 'False', 'normalized_company_name': '23andme inc'}\n",
      "247ai {'has_duplicates': 'False', 'normalized_company_name': '247ai'}\n",
      "2seventy bio inc {'has_duplicates': 'False', 'normalized_company_name': '2seventy bio inc'}\n",
      "360 behavioral health {'has_duplicates': 'False', 'normalized_company_name': '360 behavioral health'}\n",
      "365 delivery inc {'has_duplicates': 'False', 'normalized_company_name': '365 delivery inc'}\n",
      "3m hq {'has_duplicates': 'True', 'normalized_company_name': '3m'}\n",
      "3ms wonewok {'has_duplicates': 'True', 'normalized_company_name': '3m'}\n",
      "401 food llc dba merchants restaurant {'has_duplicates': 'False', 'normalized_company_name': '401 food llc'}\n",
      "48forty solutions llc {'has_duplicates': 'False', 'normalized_company_name': '48forty solutions llc'}\n",
      "4th street saloon {'has_duplicates': 'False', 'normalized_company_name': '4th street saloon'}\n",
      "507 public house {'has_duplicates': 'False', 'normalized_company_name': '507 public house'}\n",
      "7 cs maintenance at trump tower chicago {'has_duplicates': 'False', 'normalized_company_name': '7 cs maintenance at trump tower chicago'}\n",
      "8490 hospitality llc dba catch steak {'has_duplicates': 'False', 'normalized_company_name': '8490 hospitality llc'}\n",
      "8x8 inc {'has_duplicates': 'False', 'normalized_company_name': '8x8 inc'}\n",
      "99 cent only stores llc {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc conroe {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc el paso {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc katy {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc katy2 {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc mcallen {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc pasadena {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc rosenberg {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc waco {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only store llc walzem {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only stores houston 4 {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only stores llc {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n",
      "99 cents only stores san antonio {'has_duplicates': 'True', 'normalized_company_name': '99 cents only'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Generator, Tuple, Any\n",
    "import tiktoken\n",
    "from groq import Groq\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import re\n",
    "\n",
    "def save_object():\n",
    "    with open(f'warn_data.pkl', 'wb') as f:\n",
    "        pickle.dump(warn_data, f)\n",
    "\n",
    "class WarnFirmographics:\n",
    "    \"\"\"Class to process a list of companies and classify them into industries using the Groq API.\"\"\"\n",
    "    def __init__(self, api_key: str, encoding_name: str, chunk_size: int = 100, start_chunk: int = 0):\n",
    "        self.client = Groq(api_key=api_key)\n",
    "        self.encoding = tiktoken.get_encoding(encoding_name)\n",
    "        self.chunk_size = chunk_size\n",
    "        self.start_chunk = start_chunk\n",
    "        self.dict_master_response: Dict[int, Any] = {}\n",
    "\n",
    "    def load_google_sheet(self, spreadsheet_id: str, range_name: str, credentials_path: str) -> pd.DataFrame:\n",
    "        \"\"\"Load data from a Google Sheet into a pandas DataFrame.\"\"\"\n",
    "        credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "        service = build('sheets', 'v4', credentials=credentials)\n",
    "        sheet = service.spreadsheets()\n",
    "        result = sheet.values().get(spreadsheetId=spreadsheet_id, range=range_name).execute()\n",
    "        values = result.get('values', [])\n",
    "\n",
    "        if not values:\n",
    "            print('No data found.')\n",
    "            return pd.DataFrame()\n",
    "        else:\n",
    "            df = pd.DataFrame(values[1:], columns=values[0])\n",
    "            return df\n",
    "\n",
    "    # Helper function to remove punctuation and normalize text\n",
    "    def normalize_text(self, text: str) -> str:\n",
    "        # Convert to lowercase and remove punctuation\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n",
    "    \n",
    "    def data_elt(self) -> None:\n",
    "        \"\"\"Perform ETL on the WARN data.\"\"\"\n",
    "        # Load the Google Sheet\n",
    "        spreadsheet_hist_id = '1ayO8dl7sXaIYBAwkBGRUjbDms6MAbZFvvxxRp8IyxvY' # From Google Sheets URL\n",
    "        spreadsheet_2025_id = '1Qx6lv3zAL9YTsKJQNALa2GqBLXq0RER2lHvzyx32pRs' # From Google Sheets URL\n",
    "\n",
    "        range_name = 'Sheet1!A1:M'  \n",
    "        credentials_path = '../warn-analytics.json'\n",
    "\n",
    "        df_hist = warn_data.load_google_sheet(spreadsheet_hist_id, range_name, credentials_path)\n",
    "        df_2025 = warn_data.load_google_sheet(spreadsheet_2025_id, range_name, credentials_path)\n",
    "        self.df_full = pd.concat([df_hist , df_2025], ignore_index=True)\n",
    "        \n",
    "        self.df_full['WARN Received Date'] = pd.to_datetime(self.df_full['WARN Received Date'])\n",
    "        self.df_full['WARN Received Date'] = self.df_full['WARN Received Date'].dt.strftime('%Y-%m-%d')\n",
    "        self.df_full.sort_values('WARN Received Date', ascending=False, inplace=True)\n",
    "        self.df_full = self.df_full[self.df_full['WARN Received Date'] >= '2022-01-01']\n",
    "        self.df_full['company_name_normalized'] = self.df_full['Company'].apply(self.normalize_text)\n",
    "\n",
    "    def group_by_starting_letter(self, column: str) -> None:\n",
    "        \"\"\"Group values in the DataFrame by the starting letter of the specified column.\"\"\"\n",
    "        \"\"\"Allows for smarter iteration of all potential duplicates having same starting letter\"\"\"\n",
    "        self.grouped_companies = defaultdict(list)\n",
    "        list_of_companies_sorted = list(self.df_full[column].unique())\n",
    "        list_of_companies_sorted.sort()\n",
    "        \n",
    "        for value in list_of_companies_sorted:\n",
    "            if pd.notna(value):\n",
    "                first_letter = value[0].lower()\n",
    "                self.grouped_companies[first_letter].append(value)\n",
    "\n",
    "    def convert_to_dict(self, json_str: str) -> Dict[str, str]:\n",
    "        \"\"\"Convert a JSON string to a dictionary.\"\"\"\n",
    "        json_objects = json_str.strip().split('\\n')\n",
    "        json_array_str = f\"{','.join(json_objects)}\"\n",
    "        try:\n",
    "            response_list = json.loads(json_array_str)\n",
    "            response_dict = {item['company']: item['classification'] for item in response_list}\n",
    "            return response_dict\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            print(json_array_str)\n",
    "            return {}\n",
    "\n",
    "    def create_llm_query_dedupe(self) -> None:\n",
    "        \"\"\"Create an LLM query for each group of values.\"\"\"\n",
    "        self.queries_dedupe = {}\n",
    "        for letter, values in self.grouped_companies.items():\n",
    "            company_list_str = \", \".join(values)\n",
    "            query = f\"\"\"Evaluate the following comma-separated list of companies and determine which ones are likely duplicates.\n",
    "                If more than one company has the same normalized name, consider them duplicates and \"has_duplicates\" should be \"True\".                  \n",
    "                Return the result as lower-case text with double quotes in a JSON object using the format below. Only provide the JSON object, nothing else.: \n",
    "                {{\"original_company_name\": {{\"has_duplicates\": \"True\" or \"False\", \"normalized_company_name\": \"a deduplicated company name\"}}}}.\n",
    "                ---:\n",
    "                {company_list_str}\n",
    "                \"\"\"\n",
    "            self.queries_dedupe[letter] = query\n",
    "\n",
    "    def make_api_call(self, query: str) -> Tuple[int, str]:\n",
    "        \"\"\"Make an API call with the given query.\"\"\"\n",
    "        #print('current query:', query)\n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": query,\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0,\n",
    "            max_completion_tokens=32768,\n",
    "            top_p=1,\n",
    "            stream=False,\n",
    "            stop=None,\n",
    "            seed=123,\n",
    "        )\n",
    "\n",
    "        response = chat_completion.choices[0].message.content\n",
    "        json_str = f\"[{response}]\"\n",
    "    \n",
    "        return json_str\n",
    "        \n",
    "    def dedupe_normalized_company_list(self) -> None:\n",
    "        \"\"\"Call LLM to evaluate company list and determine duplicates.\"\"\"\n",
    "        self.list_normalized_companies = []\n",
    "        self.df_deduped_company_normalized = pd.DataFrame()\n",
    "\n",
    "        for key in self.queries_dedupe.keys():\n",
    "            result = self.make_api_call(self.queries_dedupe[key])\n",
    "            dict_result = json.loads(result)\n",
    "\n",
    "            transformed_list = []\n",
    "            for key_result, value_result in dict_result[0].items():\n",
    "                print(key_result, value_result)\n",
    "                transformed_dict = {'original_company_name': key_result}\n",
    "                transformed_dict.update(value_result)\n",
    "                transformed_list.append(transformed_dict)\n",
    "\n",
    "            df = pd.DataFrame(transformed_list)\n",
    "            self.df_deduped_company_normalized = pd.concat([self.df_deduped_company_normalized, df], ignore_index=True)\n",
    "            \n",
    "        # for keys, values in dict_result[0].items():\n",
    "        #     self.list_normalized_companies.append(values['normalized_company_name'])    \n",
    "\n",
    "        self.list_companies_deduped = list(set(self.df_deduped_company_normalized['normalized_company_name']))\n",
    "        self.list_companies_deduped.sort()\n",
    "\n",
    "\n",
    "    def create_llm_query_industry_classification(self, chunk: list) -> None:\n",
    "        \"\"\"Make an API call with the given chunk.\"\"\"\n",
    "        #print('current chunk:' , chunk)\n",
    "        company_list_str = \"\"\n",
    "        try:\n",
    "            company_list_str = \", \".join(chunk)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(chunk)\n",
    "        query_classification = f\"\"\"Take the list of companies provided in the COMPANY-LIST below and classify each company into exactly one of the following 14 possible industries shown below under INDUSTRIES.  \n",
    "            Return result as a JSON object: example {{\"company\":\"google\", \"classification\": \"Information\"}}.\n",
    "            Only provide the JSON object, nothing else\n",
    "            INDUSTRIES: \n",
    "            1. Construction\n",
    "            2. Education and Health Services\n",
    "            3. Finance and Insurance\n",
    "            4. Information\n",
    "            5. Leisure and Hospitality\n",
    "            6. Manufacturing\n",
    "            7. Mining, quarrying, and oil and gas extraction\n",
    "            8. Professional and Business Services\n",
    "            9. Real Estate,Rental and Leasing\n",
    "            10. Retail Trade\n",
    "            11. Transportation and Warehousing\n",
    "            12. Utilities\n",
    "            13. Wholesale Trade\n",
    "            14. Other Services\n",
    "\n",
    "            COMPANY-LIST:\n",
    "            {company_list_str}\n",
    "            \"\"\"\n",
    "        \n",
    "        return query_classification\n",
    "\n",
    "    # Function to divide the list into chunks of 100 companies\n",
    "    def chunk_list(self, lst, chunk_size, start_chunk=0):\n",
    "        \"\"\"Divide the list into chunks of specified size, starting from a specific chunk.\"\"\"\n",
    "\n",
    "        for i in range(start_chunk * chunk_size, len(lst), chunk_size):\n",
    "            list_focus = lst[i:i + chunk_size]\n",
    "            cleaned_list = [x for x in list_focus if (x != 'nan') and (x != 'None')]\n",
    "\n",
    "            yield cleaned_list #lst[i:i + chunk_size]\n",
    "\n",
    "    def process_chunks(self, start_chunk=0, end_chunk=None) -> None:\n",
    "        \"\"\"Process the list of companies in chunks and make API calls.\"\"\"\n",
    "        if (start_chunk != 0):\n",
    "            self.start_chunk = start_chunk\n",
    "        else:\n",
    "            self.start_chunk = 0\n",
    "        \n",
    "        self.ctr = self.start_chunk\n",
    "        self.chunk_list_companies_deduped = self.chunk_list(self.list_companies_deduped, chunk_size=100, start_chunk=self.start_chunk)\n",
    "        \n",
    "        self.dict_master_response = {}\n",
    "\n",
    "        end_chunk = int(len(self.list_companies_deduped) / 100) + 1\n",
    "        for chunk in self.chunk_list_companies_deduped:\n",
    "            while True:\n",
    "                try:\n",
    "                    query = self.create_llm_query_industry_classification(chunk)\n",
    "                    self.classification_json_response = self.make_api_call(query)\n",
    "                    self.classification_json_objects = self.classification_json_response.strip().split('\\n')\n",
    "                    self.classification_json_array_str = f\"{''.join(self.classification_json_objects)}\"\n",
    "                    self.classification_json_array_str = self.classification_json_array_str.replace(\"}{\" ,\"}, {\")\n",
    "                    self.classification_list_of_dicts = json.loads(self.classification_json_array_str)\n",
    "                    \n",
    "                    self.dict_master_response[self.ctr] = self.classification_list_of_dicts\n",
    "\n",
    "                    if self.ctr % 10 == 0:\n",
    "                        with open(f'dict_master_response.pkl', 'wb') as f:\n",
    "                            pickle.dump(self.dict_master_response, f)\n",
    "                        print(f\"Saved dict_master_response.pkl\")\n",
    "                    \n",
    "                    self.ctr += 1\n",
    "                    break  # Exit the WHILE loop only if the API call is successful\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"API call failed: {e}\")\n",
    "                    print(\"Waiting for 5 minutes before retrying...\")\n",
    "                    time.sleep(300)  # Wait for 5 minutes (300 seconds) before retrying\n",
    "            \n",
    "                if self.ctr > end_chunk:\n",
    "                    with open(f'dict_master_response.pkl', 'wb') as f:\n",
    "                        pickle.dump(self.dict_master_response, f)\n",
    "                    break\n",
    "\n",
    "# Example usage\n",
    "#if __name__ == \"__main__\":\n",
    "    # Change the working directory\n",
    "# os.chdir('/Users/daniel.lapushin6sense.com/Documents/GitHub/trade_advisor/llm_files')\n",
    "# print(os.getcwd())\n",
    "\n",
    "# Initialize the WarnFirmographics class\n",
    "warn_data = WarnFirmographics(api_key='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', encoding_name=\"cl100k_base\")\n",
    "warn_data.data_elt()\n",
    "warn_data.group_by_starting_letter('company_name_normalized')\n",
    "warn_data.create_llm_query_dedupe()\n",
    "warn_data.dedupe_normalized_company_list()\n",
    "warn_data.process_chunks()\n",
    "save_object()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dict_master_response.pkl\n",
      "Saved dict_master_response.pkl\n",
      "Saved dict_master_response.pkl\n",
      "Saved dict_master_response.pkl\n",
      "Saved dict_master_response.pkl\n"
     ]
    }
   ],
   "source": [
    "df_master_response = pd.DataFrame()\n",
    "\n",
    "for chunk in warn_data.dict_master_response.keys():\n",
    "    if(list(warn_data.dict_master_response[chunk][0].keys()) == ['companies']):\n",
    "        df_chunk = pd.DataFrame(warn_data.dict_master_response[chunk][0]['companies'])\n",
    "    else:\n",
    "        df_chunk = pd.DataFrame(warn_data.dict_master_response[chunk])\n",
    "    \n",
    "    df_master_response = pd.concat([df_master_response, df_chunk], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_response = pd.DataFrame()\n",
    "\n",
    "for chunk in warn_data.dict_master_response.keys():\n",
    "    if(list(warn_data.dict_master_response[chunk][0].keys()) == ['companies']):\n",
    "        df_chunk = pd.DataFrame(warn_data.dict_master_response[chunk][0]['companies'])\n",
    "    else:\n",
    "        df_chunk = pd.DataFrame(warn_data.dict_master_response[chunk])\n",
    "    \n",
    "    df_master_response = pd.concat([df_master_response, df_chunk], ignore_index=True)\n",
    "\n",
    "df_master_response.to_csv('warn_firmographics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaanapali beach hotel and the plantation inn {'has_duplicates': 'False', 'normalized_company_name': 'kaanapali beach hotel and the plantation inn'}\n",
      "kai management services llc {'has_duplicates': 'True', 'normalized_company_name': 'kai management services'}\n",
      "kaiser aluminum sherman {'has_duplicates': 'False', 'normalized_company_name': 'kaiser aluminum'}\n",
      "kaiser foundation hospitals {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals arrow {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals canyon {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals fair oaks {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals harrison {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals lakeside {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals mission {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals one {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals ordway building {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals pasadena {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitals rio {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitalslos robles {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiser foundation hospitalswalnut {'has_duplicates': 'True', 'normalized_company_name': 'kaiser foundation hospitals'}\n",
      "kaiyo furnishare inc {'has_duplicates': 'False', 'normalized_company_name': 'kaiyo'}\n",
      "kaleo {'has_duplicates': 'True', 'normalized_company_name': 'kaleo'}\n",
      "kaleo inc {'has_duplicates': 'True', 'normalized_company_name': 'kaleo'}\n",
      "kalil bottling company {'has_duplicates': 'False', 'normalized_company_name': 'kalil bottling company'}\n",
      "kalmbach media co {'has_duplicates': 'False', 'normalized_company_name': 'kalmbach media'}\n",
      "kaman precision products inc {'has_duplicates': 'False', 'normalized_company_name': 'kaman precision products'}\n",
      "kane county personnel inc dba manpower {'has_duplicates': 'False', 'normalized_company_name': 'kane county personnel'}\n",
      "kasasa ltd {'has_duplicates': 'False', 'normalized_company_name': 'kasasa'}\n",
      "kashaco inc {'has_duplicates': 'False', 'normalized_company_name': 'kashaco'}\n",
      "kauffman engineering {'has_duplicates': 'False', 'normalized_company_name': 'kauffman engineering'}\n",
      "kaygen inc {'has_duplicates': 'False', 'normalized_company_name': 'kaygen'}\n",
      "kayserroth corporation {'has_duplicates': 'False', 'normalized_company_name': 'kayserroth'}\n",
      "kbr manager llc dba kauai beach resort spa {'has_duplicates': 'False', 'normalized_company_name': 'kauai beach resort spa'}\n",
      "kcarc {'has_duplicates': 'False', 'normalized_company_name': 'kcarc'}\n",
      "kcp plumbing holdings acquisition sub llc dba steves plumbing and ac service {'has_duplicates': 'False', 'normalized_company_name': 'steves plumbing and ac service'}\n",
      "kdcone {'has_duplicates': 'False', 'normalized_company_name': 'kdcone'}\n",
      "keeco {'has_duplicates': 'True', 'normalized_company_name': 'keeco'}\n",
      "keeco llc {'has_duplicates': 'True', 'normalized_company_name': 'keeco'}\n",
      "keeko llc {'has_duplicates': 'False', 'normalized_company_name': 'keeko'}\n",
      "kehe distributors inc {'has_duplicates': 'True', 'normalized_company_name': 'kehe distributors'}\n",
      "kehe distributors incflower mound {'has_duplicates': 'True', 'normalized_company_name': 'kehe distributors'}\n",
      "kellanova company eggo plant {'has_duplicates': 'False', 'normalized_company_name': 'kellanova'}\n",
      "kelsey hospital {'has_duplicates': 'False', 'normalized_company_name': 'kelsey hospital'}\n",
      "kenco logistic services {'has_duplicates': 'True', 'normalized_company_name': 'kenco logistics'}\n",
      "kenco logistics services llc {'has_duplicates': 'True', 'normalized_company_name': 'kenco logistics'}\n",
      "kennametal inc {'has_duplicates': 'False', 'normalized_company_name': 'kennametal'}\n",
      "kenosha estates nursing and rehab {'has_duplicates': 'False', 'normalized_company_name': 'kenosha estates nursing and rehab'}\n",
      "kentucky medical services foundation inc {'has_duplicates': 'False', 'normalized_company_name': 'kentucky medical services foundation'}\n",
      "kenvue inc {'has_duplicates': 'False', 'normalized_company_name': 'kenvue'}\n",
      "keolis transit america {'has_duplicates': 'False', 'normalized_company_name': 'keolis transit america'}\n",
      "keplr vision llc {'has_duplicates': 'False', 'normalized_company_name': 'keplr vision'}\n",
      "kepro {'has_duplicates': 'False', 'normalized_company_name': 'kepro'}\n",
      "kern vineyards inc {'has_duplicates': 'False', 'normalized_company_name': 'kern vineyards'}\n",
      "kerry inc {'has_duplicates': 'False', 'normalized_company_name': 'kerry'}\n",
      "kershaw fruit and cold storage {'has_duplicates': 'False', 'normalized_company_name': 'kershaw fruit and cold storage'}\n",
      "keter us inc {'has_duplicates': 'False', 'normalized_company_name': 'keter'}\n",
      "kett engineering corporation {'has_duplicates': 'False', 'normalized_company_name': 'kett engineering'}\n",
      "keurig green mountain inc {'has_duplicates': 'False', 'normalized_company_name': 'keurig green mountain'}\n",
      "kevothermal llc {'has_duplicates': 'False', 'normalized_company_name': 'kevothermal'}\n",
      "key energy services llc {'has_duplicates': 'False', 'normalized_company_name': 'key energy services'}\n",
      "keystone foodstyson foods {'has_duplicates': 'False', 'normalized_company_name': 'keystone foods'}\n",
      "keystone powdered metal company {'has_duplicates': 'False', 'normalized_company_name': 'keystone powdered metal'}\n",
      "keystone rv company {'has_duplicates': 'False', 'normalized_company_name': 'keystone rv'}\n",
      "kgp telecommunications llc {'has_duplicates': 'False', 'normalized_company_name': 'kgp telecommunications'}\n",
      "kichler lighting llc {'has_duplicates': 'False', 'normalized_company_name': 'kichler lighting'}\n",
      "kidizen {'has_duplicates': 'False', 'normalized_company_name': 'kidizen'}\n",
      "kidthreadlandau uniforms {'has_duplicates': 'False', 'normalized_company_name': 'kidthread'}\n",
      "kimball electronics {'has_duplicates': 'False', 'normalized_company_name': 'kimball electronics'}\n",
      "kims {'has_duplicates': 'False', 'normalized_company_name': 'kims'}\n",
      "kimura enterprise inc {'has_duplicates': 'False', 'normalized_company_name': 'kimura enterprise'}\n",
      "kinecta federal credit union {'has_duplicates': 'False', 'normalized_company_name': 'kinecta federal credit union'}\n",
      "king infiniti of honolulu llc {'has_duplicates': 'False', 'normalized_company_name': 'king infiniti of honolulu'}\n",
      "kingrsquos fish house {'has_duplicates': 'True', 'normalized_company_name': 'kings fish house'}\n",
      "kings command foods llc {'has_duplicates': 'False', 'normalized_company_name': 'kings command foods'}\n",
      "kings fish house {'has_duplicates': 'True', 'normalized_company_name': 'kings fish house'}\n",
      "kings garden inc {'has_duplicates': 'False', 'normalized_company_name': 'kings garden'}\n",
      "kingsford manufacturing company {'has_duplicates': 'False', 'normalized_company_name': 'kingsford manufacturing'}\n",
      "kinhdo restaurant {'has_duplicates': 'False', 'normalized_company_name': 'kinhdo restaurant'}\n",
      "kinze manufacturing inc {'has_duplicates': 'False', 'normalized_company_name': 'kinze manufacturing'}\n",
      "kioxia america inc {'has_duplicates': 'False', 'normalized_company_name': 'kioxia america'}\n",
      "kipp memphis academy middle school {'has_duplicates': 'False', 'normalized_company_name': 'kipp memphis academy middle school'}\n",
      "kira government services {'has_duplicates': 'True', 'normalized_company_name': 'kira'}\n",
      "kira training services {'has_duplicates': 'True', 'normalized_company_name': 'kira'}\n",
      "kirby perkins construction {'has_duplicates': 'False', 'normalized_company_name': 'kirby perkins construction'}\n",
      "kirklands home {'has_duplicates': 'False', 'normalized_company_name': 'kirklands home'}\n",
      "kiss distribution corp {'has_duplicates': 'False', 'normalized_company_name': 'kiss distribution'}\n",
      "kitayama brothers inc {'has_duplicates': 'False', 'normalized_company_name': 'kitayama brothers'}\n",
      "kitty hawk corporation location 1 {'has_duplicates': 'True', 'normalized_company_name': 'kitty hawk corporation'}\n",
      "kitty hawk corporation location 2 {'has_duplicates': 'True', 'normalized_company_name': 'kitty hawk corporation'}\n",
      "kitty hawk corporation location 3 {'has_duplicates': 'True', 'normalized_company_name': 'kitty hawk corporation'}\n",
      "kitty hawk corporation location 4 {'has_duplicates': 'True', 'normalized_company_name': 'kitty hawk corporation'}\n",
      "kjs hideaway {'has_duplicates': 'False', 'normalized_company_name': 'kjs hideaway'}\n",
      "kla corporation {'has_duplicates': 'False', 'normalized_company_name': 'kla corporation'}\n",
      "klarna llc {'has_duplicates': 'False', 'normalized_company_name': 'klarna'}\n",
      "klaussner furniture industries inc {'has_duplicates': 'False', 'normalized_company_name': 'klaussner furniture industries'}\n",
      "kliklok llc {'has_duplicates': 'False', 'normalized_company_name': 'kliklok'}\n",
      "knau insulation inc {'has_duplicates': 'False', 'normalized_company_name': 'knau insulation'}\n",
      "knowles precision devices {'has_duplicates': 'False', 'normalized_company_name': 'knowles precision devices'}\n",
      "knox attorney service inc {'has_duplicates': 'False', 'normalized_company_name': 'knox attorney service'}\n",
      "knutson construction services midwest inc {'has_duplicates': 'False', 'normalized_company_name': 'knutson construction services midwest'}\n",
      "kodi collective llc {'has_duplicates': 'False', 'normalized_company_name': 'kodi collective'}\n",
      "kohana coffee company {'has_duplicates': 'False', 'normalized_company_name': 'kohana coffee company'}\n",
      "kohler co {'has_duplicates': 'True', 'normalized_company_name': 'kohler'}\n",
      "kohler co vitreous operations {'has_duplicates': 'True', 'normalized_company_name': 'kohler'}\n",
      "kohls inc {'has_duplicates': 'False', 'normalized_company_name': 'kohls'}\n",
      "kona transportation company inc {'has_duplicates': 'False', 'normalized_company_name': 'kona transportation company'}\n",
      "konica minolta business solutions usa inc {'has_duplicates': 'False', 'normalized_company_name': 'konica minolta business solutions usa'}\n",
      "kpfg {'has_duplicates': 'False', 'normalized_company_name': 'kpfg'}\n",
      "kra {'has_duplicates': 'False', 'normalized_company_name': 'kra'}\n",
      "kraft heinz foods company {'has_duplicates': 'False', 'normalized_company_name': 'kraft heinz foods'}\n",
      "krazy bling boutique {'has_duplicates': 'False', 'normalized_company_name': 'krazy bling boutique'}\n",
      "krispy kreme doughnut corporation {'has_duplicates': 'False', 'normalized_company_name': 'krispy kreme doughnut'}\n",
      "kroger {'has_duplicates': 'True', 'normalized_company_name': 'kroger'}\n",
      "kroger fulfillment network llc {'has_duplicates': 'True', 'normalized_company_name': 'kroger fulfillment network'}\n",
      "kroger fulfillment network llcaustin {'has_duplicates': 'True', 'normalized_company_name': 'kroger fulfillment network'}\n",
      "kroger fulfillment network llcsan antonio {'has_duplicates': 'True', 'normalized_company_name': 'kroger fulfillment network'}\n",
      "kuehne nagel {'has_duplicates': 'True', 'normalized_company_name': 'kuehne nagel'}\n",
      "kuehne nagel inc {'has_duplicates': 'True', 'normalized_company_name': 'kuehne nagel'}\n",
      "kuehne nagel kn {'has_duplicates': 'True', 'normalized_company_name': 'kuehne nagel'}\n",
      "kuehnenagel {'has_duplicates': 'True', 'normalized_company_name': 'kuehne nagel'}\n",
      "kuka toledo production operations llc {'has_duplicates': 'False', 'normalized_company_name': 'kuka toledo production operations'}\n",
      "kunzler company inc {'has_duplicates': 'False', 'normalized_company_name': 'kunzler company'}\n",
      "kuubix global llc {'has_duplicates': 'False', 'normalized_company_name': 'kuubix global'}\n",
      "kyowa kirin inc {'has_duplicates': 'False', 'normalized_company_name': 'kyowa kirin'}\n",
      "kyros {'has_duplicates': 'False', 'normalized_company_name': 'kyros'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_company_name</th>\n",
       "      <th>has_duplicates</th>\n",
       "      <th>normalized_company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaanapali beach hotel and the plantation inn</td>\n",
       "      <td>False</td>\n",
       "      <td>kaanapali beach hotel and the plantation inn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kai management services llc</td>\n",
       "      <td>True</td>\n",
       "      <td>kai management services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kaiser aluminum sherman</td>\n",
       "      <td>False</td>\n",
       "      <td>kaiser aluminum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kaiser foundation hospitals</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiser foundation hospitals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kaiser foundation hospitals arrow</td>\n",
       "      <td>True</td>\n",
       "      <td>kaiser foundation hospitals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>kuka toledo production operations llc</td>\n",
       "      <td>False</td>\n",
       "      <td>kuka toledo production operations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>kunzler company inc</td>\n",
       "      <td>False</td>\n",
       "      <td>kunzler company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>kuubix global llc</td>\n",
       "      <td>False</td>\n",
       "      <td>kuubix global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>kyowa kirin inc</td>\n",
       "      <td>False</td>\n",
       "      <td>kyowa kirin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>kyros</td>\n",
       "      <td>False</td>\n",
       "      <td>kyros</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            original_company_name has_duplicates  \\\n",
       "0    kaanapali beach hotel and the plantation inn          False   \n",
       "1                     kai management services llc           True   \n",
       "2                         kaiser aluminum sherman          False   \n",
       "3                     kaiser foundation hospitals           True   \n",
       "4               kaiser foundation hospitals arrow           True   \n",
       "..                                            ...            ...   \n",
       "116         kuka toledo production operations llc          False   \n",
       "117                           kunzler company inc          False   \n",
       "118                             kuubix global llc          False   \n",
       "119                               kyowa kirin inc          False   \n",
       "120                                         kyros          False   \n",
       "\n",
       "                          normalized_company_name  \n",
       "0    kaanapali beach hotel and the plantation inn  \n",
       "1                         kai management services  \n",
       "2                                 kaiser aluminum  \n",
       "3                     kaiser foundation hospitals  \n",
       "4                     kaiser foundation hospitals  \n",
       "..                                            ...  \n",
       "116             kuka toledo production operations  \n",
       "117                               kunzler company  \n",
       "118                                 kuubix global  \n",
       "119                                   kyowa kirin  \n",
       "120                                         kyros  \n",
       "\n",
       "[121 rows x 3 columns]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result = warn_data.make_api_call(warn_data.queries_dedupe['k'])\n",
    "#dict_result = json.loads(result)\n",
    "\n",
    "\n",
    "# Transform the list of dictionaries into a format suitable for a DataFrame\n",
    "transformed_list = []\n",
    "for key, value in dict_result[0].items():\n",
    "    print(key, value)\n",
    "    transformed_dict = {'original_company_name': key}\n",
    "    transformed_dict.update(value)\n",
    "    transformed_list.append(transformed_dict)\n",
    "\n",
    "df = pd.DataFrame(transformed_list)\n",
    "\n",
    "#     print(item)\n",
    "#     print(dict_result)\n",
    "    # for key, value in item.items():\n",
    "    #     transformed_dict = {'original_company_name': key}\n",
    "    #     transformed_dict.update(value)\n",
    "    #     transformed_list.append(transformed_dict)\n",
    "\n",
    "# Convert the transformed list into a DataFrame\n",
    "#df = pd.DataFrame(transformed_list)\n",
    "# Print the DataFrame\n",
    "#print(df)\n",
    "#pd.DataFrame(dict_result[0].items())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# df_normalized_companies = pd.read_csv('/Users/daniel.lapushin6sense.com/Documents/GitHub/trade_advisor/llm_files/normalized_companies.csv')\n",
    "# #list(df_normalized_companies['normalized'])\n",
    "# df_normalized_companies.iloc[0:4192].tail()\n",
    "\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "def load_google_sheet(spreadsheet_id, range_name, credentials_path):\n",
    "    \"\"\"\n",
    "    Load data from a Google Sheet into a pandas DataFrame\n",
    "    \n",
    "    Args:\n",
    "        spreadsheet_id (str): The ID of the Google Sheet (from the URL)\n",
    "        range_name (str): The range to read (e.g. 'Sheet1!A1:D100')\n",
    "        credentials_path (str): Path to the service account credentials JSON file\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the sheet data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load credentials from service account file\n",
    "        credentials = service_account.Credentials.from_service_account_file(\n",
    "            credentials_path,\n",
    "            scopes=['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "        )\n",
    "\n",
    "        # Build the Sheets API service\n",
    "        service = build('sheets', 'v4', credentials=credentials)\n",
    "        \n",
    "        # Call the Sheets API to get the data\n",
    "        sheet = service.spreadsheets()\n",
    "        result = sheet.values().get(\n",
    "            spreadsheetId=spreadsheet_id,\n",
    "            range=range_name\n",
    "        ).execute()\n",
    "        \n",
    "        # Get the values from the result\n",
    "        values = result.get('values', [])\n",
    "        \n",
    "        if not values:\n",
    "            print('No data found in sheet')\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(values[1:], columns=values[0])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Google Sheet: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example usage:\n",
    "spreadsheet_hist_id = '1ayO8dl7sXaIYBAwkBGRUjbDms6MAbZFvvxxRp8IyxvY' # From Google Sheets URL\n",
    "spreadsheet_2025_id = '1Qx6lv3zAL9YTsKJQNALa2GqBLXq0RER2lHvzyx32pRs' # From Google Sheets URL\n",
    "\n",
    "range_name = 'Sheet1!A1:M'  \n",
    "credentials_path = '../warn-analytics.json'\n",
    "\n",
    "df_hist = load_google_sheet(spreadsheet_hist_id, range_name, credentials_path)  \n",
    "df_2025 = load_google_sheet(spreadsheet_2025_id, range_name, credentials_path)\n",
    "\n",
    "df_full = pd.concat([df_hist , df_2025], ignore_index=True)\n",
    "df_full['WARN Received Date'] = pd.to_datetime(df_full['WARN Received Date'])\n",
    "df_full['WARN Received Date'] = df_full['WARN Received Date'].dt.strftime('%Y-%m-%d')\n",
    "df_full.sort_values('WARN Received Date', ascending=False, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company to Industry mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "---\n",
    "title: Process\n",
    "---\n",
    "flowchart TD\n",
    "    A[Load WARN Dataset \n",
    "    through Google API client]\n",
    "    B[Extract Company Names if \n",
    "    layoffs happened \n",
    "    after 2021]\n",
    "    C[Use LLM to normalize \n",
    "    company names]\n",
    "    D[Use LLM to determine \n",
    "    industry of normalized\n",
    "    company name]\n",
    "    \n",
    "    A --> B\n",
    "    B --> C\n",
    "    C --> D\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
